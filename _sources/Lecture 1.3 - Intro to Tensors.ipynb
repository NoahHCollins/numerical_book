{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f6f398f",
   "metadata": {},
   "source": [
    "# Intro to Tensors\n",
    "\n",
    "Lecture 1.3  \n",
    "Saskia Goes, s.goes@imperial.ac.uk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c98df7a-ece6-40d2-b456-3a458b706642",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "```{contents}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a3c374",
   "metadata": {},
   "source": [
    "## Learning outcomes\n",
    "\n",
    "- Be able to perform vector/tensor operations (addition,\n",
    "multiplication) on Cartesian orthonormal bases\n",
    "- Be able to do basic vector/tensor calculus (time and\n",
    "space derivatives, divergence, curl of a vector field)\n",
    "on these bases.\n",
    "- Perform transformation of a vector from one to\n",
    "another Cartesian basis.\n",
    "- Understand differences/commonalities tensor and\n",
    "vector\n",
    "- Use index notation and Einstein convention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7ced51",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    "- Tensors are a generalisation of vectors to more\n",
    "dimensions\n",
    "- Use when properties depend on direction in\n",
    "more than one way.\n",
    "- A physical quantity that is independent of\n",
    "coordinate system is used\n",
    "- Derives from the word tension (= stress)\n",
    "- Stress tensor is an example\n",
    "- Not just a multidimensional array\n",
    "\n",
    "Further examples of the uses of tensors include: Stress, strain, and moment tensors. Electrostatics, electrodynamics, rotation, crystal properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e5989e",
   "metadata": {},
   "source": [
    "### Tensor Rank\n",
    "Tensors describe properties that depend on direction\n",
    "\n",
    "Tensor rank 0 - **scalar - independent of direction**  \n",
    "Tensor rank 1 - **vector - depends on direction in 1 way**  \n",
    "Tensor rank 2 - **tensor - depends on direction in 2 ways**\n",
    "\n",
    "\n",
    "```{figure} Images/Lecture1.3/Tensor_rank.png\n",
    ":width: 75%\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfd8543",
   "metadata": {},
   "source": [
    "### Notation <a name = \"notation\">\n",
    "\n",
    "- Tensors as $\\mathbf{T}$\n",
    "- Second order tensors wirtten as $\\bar{\\bar{\\mathbf{T}}}$ or $\\underline{\\underline{\\mathbf{T}}}$ \n",
    "- Index notation: $T_{ij}$ where $i,j=x,y,z$ or $i,j=1,2,3$\n",
    "- For higher order: $T_{ijkl}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f627727",
   "metadata": {},
   "source": [
    "### An Example Tensor\n",
    "\n",
    "Here is an example of a tensor, the gradient of velocity that depends on direction in two ways\n",
    "\n",
    "$$\n",
    "\\nabla \\mathbf{v} = \\frac{\\partial v_j}{\\partial x_i} = \n",
    "\\left[\\begin{array}{cc}\n",
    "\\frac{\\partial v_1}{\\partial x_1} & \\frac{\\partial v_2}{\\partial x_1} & \\frac{\\partial v_3}{\\partial x_1} \\\\\n",
    "\\frac{\\partial v_1}{\\partial x_2} & \\frac{\\partial v_2}{\\partial x_2} & \\frac{\\partial v_3}{\\partial x_2} \\\\\n",
    "\\frac{\\partial v_1}{\\partial x_3} & \\frac{\\partial v_2}{\\partial x_3} & \\frac{\\partial v_3}{\\partial x_3} \\\\\n",
    "\\end{array}\\right]\n",
    "$$  \n",
    "\n",
    "Where each numerator, $v_j$, is a component of velocity and each denominator $x_i$ is the direction which the spatial variation, $\\frac{\\partial v_j}{\\partial x_i}$ is in.\n",
    "\n",
    "This tensor gradient definition is common in fluid dynamics  \n",
    "<span style=\"color:red\">\n",
    "*Note: some texts (including Lai et al., Reddy)\n",
    "use a transposed definition:* </span>\n",
    "\n",
    "$$\n",
    "\\nabla \\mathbf{v} = \\frac{\\partial v_j}{\\partial x_i} = \n",
    "\\left[\\begin{array}{cc}\n",
    "\\frac{\\partial v_1}{\\partial x_1} & \\frac{\\partial v_1}{\\partial x_2} & \\frac{\\partial v_1}{\\partial x_3} \\\\\n",
    "\\frac{\\partial v_2}{\\partial x_1} & \\frac{\\partial v_2}{\\partial x_2} & \\frac{\\partial v_2}{\\partial x_3} \\\\\n",
    "\\frac{\\partial v_3}{\\partial x_1} & \\frac{\\partial v_3}{\\partial x_2} & \\frac{\\partial v_3}{\\partial x_3} \\\\\n",
    "\\end{array}\\right]\n",
    "$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65169784",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Stress Tensor <a name = \"stress_tensor\">\n",
    "- *Body forces* - depend on volume, e.g. gravity\n",
    "- *Surface forces* - depend on surface area, e.g. friction\n",
    "\n",
    "Forces introduce a state of stress in a body\n",
    "\n",
    "```{figure} Images/Lecture1.3/Stress_tensor.png\n",
    ":width: 75%\n",
    "```\n",
    "\n",
    "- the $\\Delta\\mathbf{f}$ necessary to maintain equilibrium depends on\n",
    "orientation of the plane, $\\hat{\\mathbf{n_1}}$\n",
    "- the traction, $\\mathbf{t_1}$ on the surface is defined as:\n",
    "    \n",
    "$$\n",
    "\\mathbf{t_1} = \\mathbf{t}(\\mathbf{\\hat{n_1}}) = \\lim_{\\Delta A \\rightarrow 0} \\frac{\\Delta\\mathbf{f}}{\\Delta A_1}\n",
    "$$  \n",
    "    \n",
    "$$\n",
    "\\mathbf{t_1} = (\\sigma_{11}, \\sigma_{12}, \\sigma_{13})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma_{11} = \\lim_{\\Delta A \\rightarrow 0} \\frac{\\Delta\\mathbf{f_1}}{\\Delta A_1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma_{12} = \\lim_{\\Delta A \\rightarrow 0} \\frac{\\Delta\\mathbf{f_2}}{\\Delta A_1} \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma_{13} = \\lim_{\\Delta A \\rightarrow 0} \\frac{\\Delta\\mathbf{f_3}}{\\Delta A_1}\n",
    "$$\n",
    "\n",
    "Nine components are needed to fully describe the stress. \n",
    "    \n",
    "$$\\sigma_{11}, \\sigma_{12}, \\sigma_{13} \\rightarrow \\Delta A_1$$\n",
    "    \n",
    "$$\\sigma_{21}, \\sigma_{22}, \\sigma_{23} \\rightarrow \\Delta A_2$$\n",
    "    \n",
    "$$\\sigma_{31}, \\sigma_{32}, \\sigma_{33} \\rightarrow \\Delta A_3$$ \n",
    "\n",
    "Generalised stress:\n",
    "    \n",
    "$$\n",
    "\\sigma_{ij} = \\left[\\begin{array}{cc}\n",
    "\\sigma_{11} & \\sigma_{12} & \\sigma_{13} \\\\\n",
    "\\sigma_{21} & \\sigma_{22} & \\sigma_{23} \\\\\n",
    "\\sigma_{31} & \\sigma_{32} & \\sigma_{33} \\\\\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "    \n",
    "- First index indicates orientation of plane\n",
    "- Second index indicates orientation of force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9d3f30",
   "metadata": {},
   "source": [
    "### Distinction between tensor and its matrix <a name = \"distinction\">\n",
    "\n",
    "- Tensor – a physical quantity that is independent of\n",
    "coordinate system used\n",
    "- Matrix of a tensor – contains components of that tensor\n",
    "in a particular coordinate frame\n",
    "\n",
    "You could test that indeed tensor addition and multiplication\n",
    "satisfy transformation laws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7200a794",
   "metadata": {},
   "source": [
    "## Tensor Operations <a name = \"tensor_operations\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948d6217",
   "metadata": {},
   "source": [
    "### Summation (Einstein) Convention <a name = \"summation_einstein_convention\">\n",
    "    \n",
    "When an index in a single term is a duplicate, dummy index, summation is implied without writing the summation symbol. An example is shown below:\n",
    "   \n",
    "    \n",
    "$$\n",
    "a_1 v_1 + a_2 v_2 + a_3 v_3 = \\sum_{i=1}^3 a_i v_i = a_i v_i\n",
    "$$\n",
    "    \n",
    "An example with three terms is shown below:  \n",
    "    \n",
    "    \n",
    "$$a_{ij} x_i y_j = \\sum_{i=1}^3 \\sum_{j=1}^3 a_{ij} x_i y_j$$\n",
    "    \n",
    "$$= a_{11} x_1 y_1 + a_{12} x_1 y_2 + a_{13} x_1 y_3$$\n",
    "    \n",
    "$$= a_{21} x_2 y_1 + a_{22} x_2 y_2 + a_{23} x_2 y_3$$ \n",
    "    \n",
    "$$= a_{31} x_3 y_1 + a_{32} x_3 y_2 + a_{33} x_3 y_3$$ \n",
    "    \n",
    "    \n",
    "The example below is **invalid**, as there are indices repeated more than twice\n",
    "    \n",
    "$$\n",
    "\\sum_{i=1}^3 a_i b_i v_i \\neq a_i b_i v_i\n",
    "$$\n",
    "    \n",
    "    \n",
    "*For more details see https://en.wikipedia.org/wiki/Einstein_notation*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a53fc4b",
   "metadata": {},
   "source": [
    "### Notation Conventions <a name = \"notation_conventions\">\n",
    "\n",
    "- Index notation - $\\alpha_{ij} x_i y_j = \\sum_{i=1}^3 \\sum_{j=1}^3 \\alpha_{ij} x_i y_j$\n",
    "- Matrix-vector notation - \n",
    "$\\mathbf{x^T A y} = (\\begin{array} \\\\ x_1 & x_2 & x_3\\end{array})$\n",
    "$\\left[\\begin{array} \\\\ \n",
    "    \\alpha_{11} & \\alpha_{12} & \\alpha_{13} \\\\\n",
    "    \\alpha_{11} & \\alpha_{12} & \\alpha_{13} \\\\\n",
    "    \\alpha_{11} & \\alpha_{12} & \\alpha_{13} \\\\\n",
    "\\end{array}\\right]$\n",
    "$\\left(\\begin{array} \\\\ y_1 \\\\ y_2 \\\\ y_3\\end{array}\\right)$\n",
    "- Other versions of index notation - $x_i \\alpha_{ij} y_j = \\alpha_{ij} x_i y_j = \\alpha_{ij} y_j x_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8fbb79",
   "metadata": {},
   "source": [
    "### Dummy vs Free Index <a name = \"dummy_index\">\n",
    "    \n",
    "$$ \n",
    "a_1 v_2 + a_2 v_2 + a_3 v_3 = \\sum_{i=1}^3 a_i v_i = \\sum_{k=1}^3 a_k v_k \n",
    "$$\n",
    "    \n",
    "- $i,k$ - dummy index: appears in duplicates and can be\n",
    "substituted without changing equation\n",
    "    \n",
    "$$F_j = A_j \\sum_{i=1}^3 B_i C_i$$\n",
    "\n",
    "$$↓$$\n",
    "    \n",
    "$$F_1 = A_1 (B_1 C_1 + B_2 C_2 + B_3 C_3)$$\n",
    "    \n",
    "$$F_2 = A_2 (B_1 C_1 + B_2 C_2 + B_3 C_3)$$ \n",
    "    \n",
    "$$F_3 = A_3 (B_1 C_1 + B_2 C_2 + B_3 C_3)$$\n",
    "    \n",
    "- $j$ - free index, appears once in each term of the equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0128a601-e24d-4f1c-869e-ba270faf0e0c",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "1. Which indices in the following equation are dummy indices, and which are free. How many equations are there and how many terms in each?\n",
    "\n",
    "$$ g_k = h_k(2-3a_i b_i)-p_jq_jf_k $$\n",
    "\n",
    "\n",
    "2. Which of the following are valid expressions?\n",
    "\n",
    "- $a_m b_s = c_m (d_r-f_r)$\n",
    "- $x_i x_i = r^2$\n",
    "- $a_i b_j c_j = 3$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17db5cd0-6d44-4fac-b4cb-769d65f1072f",
   "metadata": {},
   "source": [
    "### Addition and Subtraction of Tensors\n",
    "\n",
    "$\\mathbf{W} = a\\mathbf{T}+b\\mathbf{S}$  \n",
    "add each component: $W_{ijkl} = aT_{ijkl} + bS_{ijkl}$  \n",
    "\n",
    "$\\mathbf{T}$ and $\\mathbf{S}$ must have the same rank, dimension and units.  \n",
    "$\\mathbf{W}$ has takes the same rank, dimension and units as $\\mathbf{T}$ and $\\mathbf{S}$  \n",
    "\n",
    "$\\mathbf{T}$ and $\\mathbf{S}$ are tensors, hence $\\mathbf{W}$ is a tensor. Tensor addition is commutative and associative.  \n",
    "This is the same as how vectors and matrices are added. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaae5f2-b8c5-4751-b724-975dffa5daa6",
   "metadata": {},
   "source": [
    "### Multiplication of Tensors\n",
    "\n",
    "#### Inner product\n",
    "\n",
    "**Inner product = dot product**\n",
    "\n",
    "$\\mathbf{W} = \\mathbf{T \\cdot S}$ involves contraction over one index: $W_{ik} = T_{ij} S_{jk}$, as normal matrix and matrix-vector multiplication.\n",
    "\n",
    "$\\mathbf{T}$ and $\\mathbf{S}$ can have different rank, but the same dimension.  \n",
    "rank of $\\mathbf{W} = $ rank of $\\mathbf{T}$ + rank of $\\mathbf{S} - 2$, dimensions as $\\mathbf{T}$ and $\\mathbf{S}$ units as product of units $\\mathbf{T}$ and $\\mathbf{S}$  \n",
    "\n",
    "$\\mathbf{T}$ and $\\mathbf{S}$ are tensors, hence $\\mathbf{W}$ is a tensor.  \n",
    "\n",
    "Examples: \n",
    "- $\\lvert \\mathbf{v} \\rvert^2 = \\mathbf{v \\cdot v}$\n",
    "- $\\mathbf{\\sigma} = \\mathbf{C:\\epsilon}$ or $\\sigma{ij} = C_{ijkl} \\epsilon_{kl}$ - Hooke's Law"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9311509c-74a9-4bb0-b6ac-a27732f0dd49",
   "metadata": {},
   "source": [
    "#### Tensor product\n",
    "\n",
    "**Tensor product = outer product = dyadic product $\\neq$ cross product**\n",
    "\n",
    "$\\mathbf{W} = \\mathbf{TS}$ is often written as $\\mathbf{W}  = \\mathbf{T \\otimes S}$  \n",
    "No contraction: $W_{ijkl} = T_{ij} S_{kl}$\n",
    "\n",
    "$\\mathbf{T}$ and $\\mathbf{S}$ can have different rank, but same dimension.  \n",
    "Rank of $\\mathbf{W}$ = rank of $\\mathbf{T}$ + rank of $\\mathbf{S}$, dimension as $\\mathbf{T}$ and $\\mathbf{S}$, units as product of units $\\mathbf{T}$ and $\\mathbf{S}$.\n",
    "\n",
    "$\\mathbf{T}$ and $\\mathbf{S}$ are tensors, hence $\\mathbf{W}$ is a tensor.\n",
    "\n",
    "Examples:\n",
    "- $\\mathbf{\\nabla v}$ (gradient of a vector) $\\neq \\mathbf{ \\nabla \\cdot v}$ (divergence)\n",
    "\n",
    "*remember that gradient is a vector* $ \\nabla = \\left( \\frac{\\partial}{\\partial x_1}, \\frac{\\partial}{\\partial x_2}, \\frac{\\partial}{\\partial x_3} \\right)$\n",
    "\n",
    "**For both multiplications**\n",
    "\n",
    "- Distributive: $\\mathbf{A(B+C) = AB + AC}$\n",
    "- Associative: $\\mathbf{A(BC) = (AB)C}$\n",
    "- Not commutative: $\\mathbf{TS \\neq ST}$ and $\\mathbf{T \\cdot S \\neq S \\cdot T}$   \n",
    "However: $\\mathbf{T\\cdot S = S^T \\cdot T^T}$  \n",
    "And: $\\mathbf{ab = (ba)^T)}$ but only for rank 2\n",
    "\n",
    "Remember **transpose:** $\\mathbf{a \\cdot T \\cdot b = b \\cdot T^T \\cdot a} \\longrightarrow T_{ji} = T_{ij}^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b177948f-24a2-4689-aa25-ecca198ef42d",
   "metadata": {},
   "source": [
    "### Special tensor - The Kronecker delta\n",
    "\n",
    "$\\mathbf{\\delta_{ij}} = \\mathbf{\\hat{e_i} \\cdot \\hat{e_j}}$  \n",
    "$\\delta_{ij} = 1$ for $i = j$, $\\delta_{ij} = 0$ for $i \\neq j$  \n",
    "\n",
    "In 3-D:\n",
    "\n",
    "$$ \\mathbf{\\delta =  I} = \\left[\\begin{array}\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{array}\\right]$$\n",
    "\n",
    "$\\mathbf{T \\cdot \\delta = T \\cdot I = T}$ or $T_{ij} \\delta {jk} = T_{ik}$\n",
    "\n",
    "Isotropic tensors, invariant upon coordinate transformation:\n",
    "- scalars\n",
    "- $\\mathbf{0}$ vector\n",
    "- $\\delta_{ij}$  \n",
    "\n",
    "$\\mathbf{\\delta}$ is isotropic: $\\delta_{ij} = \\delta_{ij}^{'}$ upon coordinate transformation can be used to write dot product: $T_{ij} S_{jl} = T_{ij} S_{kl} \\delta_{jk}$ can be used to write trace: $A_{ii} = A_{ij} \\delta_{ij}$.  \n",
    "Orthonormal transformation: $\\alpha_{ij} \\alpha_{jk}^T = \\delta_{ik}$\n",
    "\n",
    "**See Exercise 8**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d080b1-f549-40e3-af16-df942872fe3c",
   "metadata": {},
   "source": [
    "### Special tensor - Permutation symbol \n",
    "\n",
    "$\\epsilon_{ijk} = (\\mathbf{\\hat{e_i}} \\times \\mathbf{\\hat{e_j}}) \\cdot \\mathbf{\\hat{e_k}}$  \n",
    "$\\epsilon_{ijk} = 1$ if $i,j,k$ are an even permutation of 1,2,3  \n",
    "$\\epsilon_{ijk} = -1$ if $i,j,k$ are an odd permutation of 1,2,3  \n",
    "$\\epsilon_{ijk} = 0$ for all other $i,j,k$\n",
    "\n",
    "*An even permutation follows the order 1 - 2 - 3, an odd permutation follows the order 1 - 3 - 2*\n",
    "\n",
    "```{figure} Images/Lecture1.3/even_perm.png\n",
    ":width: 10%\n",
    "```\n",
    "\n",
    "Example:  \n",
    "- $\\epsilon_{123} = \\epsilon_{231} = \\epsilon_{312} = 1$\n",
    "- $\\epsilon_{213} = \\epsilon_{321} = \\epsilon_{132} = -1$\n",
    "- $\\epsilon_{111} = \\epsilon_{112} = \\epsilon_{222} = ... = 0$\n",
    "\n",
    "Note that $\\epsilon_{ijk}a_ib_j\\hat{e_k}$ where $\\hat{e_k}$ is the unit vector in $k$ direction is index notation for cross product $\\mathbf{a \\times b}$\n",
    "\n",
    "Useful identity: $\\epsilon_{ijm} \\epsilon_{klm} = \\delta_{ik} \\delta_{jl} - \\delta_{il} \\delta_{jk}$\n",
    "\n",
    "**See Exercise 8**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed585895-7ef4-40dd-a166-e5aac68b82b3",
   "metadata": {},
   "source": [
    "### Vector Derivatives - Curl\n",
    "\n",
    "Curl of a vector: \n",
    "\n",
    "$$\\nabla \\times \\mathbf{v} =\n",
    "\\epsilon_{ijk} \\frac{\\partial}{\\partial x_i} v_j \\mathbf{\\hat{e_k}} = \n",
    "\\left(\\begin{array}\\\n",
    "\\frac{\\partial v_3}{ \\partial x_2} - \\frac{\\partial v_2}{ \\partial x_3} \\\\ \n",
    "\\frac{\\partial v_1}{ \\partial x_3} - \\frac{\\partial v_3}{ \\partial x_1} \\\\ \n",
    "\\frac{\\partial v_2}{ \\partial x_1} - \\frac{\\partial v_1}{ \\partial x_2} \\\\\n",
    "\\end{array}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c5461f-0eb7-403f-862a-d08f9f67d5c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Some Tensor Calculus\n",
    "\n",
    "Gradient of a vector is a tensor:\n",
    "\n",
    "$$\\nabla \\mathbf{v} =\n",
    "\\frac{\\partial v_j}{\\partial x_i} v_j = \n",
    "\\left(\\begin{array}\\\n",
    "\\frac{\\partial v_1}{ \\partial x_1} & \\frac{\\partial v_2}{ \\partial x_1} & \\frac{\\partial v_3}{ \\partial x_1} \\\\ \n",
    "\\frac{\\partial v_1}{ \\partial x_2} & \\frac{\\partial v_2}{ \\partial x_2} & \\frac{\\partial v_3}{ \\partial x_2} \\\\ \n",
    "\\frac{\\partial v_1}{ \\partial x_3} & \\frac{\\partial v_2}{ \\partial x_3} & \\frac{\\partial v_3}{ \\partial x_3} \\\\ \n",
    "\\end{array}\\right)$$\n",
    "\n",
    "Such that the change $\\mathbf{dv}$ in field $\\mathbf{v}$ is: $\\mathbf{dv} = \\mathbf{dx \\cdot \\nabla v}$  \n",
    "\n",
    "**Divergence of a vector:**   \n",
    "\n",
    "$$ \\nabla \\cdot \\mathbf{v} = \\frac{\\partial v_i}{\\partial x_i} = \\frac{\\partial v_1}{\\partial x_1} + \\frac{\\partial v_2}{\\partial x_2} + \\frac{\\partial v_3}{\\partial x_3} $$\n",
    "\n",
    "$$ \\nabla \\cdot \\mathbf{v} = tr(\\nabla \\mathbf{v} )$$\n",
    "\n",
    "<span style=\"color: red;\"> Trace </span> of a tensor is the sum of diagonal elements\n",
    "\n",
    "**Divergence of a tensor:**  \n",
    "\n",
    "$$ \\nabla \\cdot T = \\frac{\\partial T_{ij}}{\\partial x_j} =\n",
    "\\left(\\begin{array}\\\n",
    "\\frac{\\partial T_{1j}}{ \\partial x_j} \\\\ \n",
    "\\frac{\\partial T_{2j}}{ \\partial x_j} \\\\ \n",
    "\\frac{\\partial T_{3j}}{ \\partial x_j} \\\\\n",
    "\\end{array}\\right) =\n",
    "\\left(\\begin{array}\\\n",
    "\\frac{\\partial T_{11}}{ \\partial x_1} + \\frac{\\partial T_{12}}{ \\partial x_2} + \\frac{\\partial T_{13}}{ \\partial x_3} \\\\ \n",
    "\\frac{\\partial T_{21}}{ \\partial x_1} + \\frac{\\partial T_{22}}{ \\partial x_2} + \\frac{\\partial T_{23}}{ \\partial x_3} \\\\\n",
    "\\frac{\\partial T_{31}}{ \\partial x_1} + \\frac{\\partial T_{32}}{ \\partial x_2} + \\frac{\\partial T_{33}}{ \\partial x_3} \\\\\n",
    "\\end{array}\\right)$$\n",
    "\n",
    "Laplacian = div(grad f), where f is a scalar function:  \n",
    "\n",
    "$$\\nabla \\cdot \\nabla f = \\nabla^2 f = \\Delta f = \n",
    "\\frac{\\partial^2}{\\partial x_i \\partial x_i} =\n",
    "\\frac{\\partial^2f}{\\partial x_1^2} + \\frac{\\partial^2f}{\\partial x_2^2} + \\frac{\\partial^2f}{\\partial x_3^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdadfdb-7516-4dfd-9571-022897c8288f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Vectors  \n",
    "– Addition, linear independence  \n",
    "– Orthonormal Cartesian bases, transformation  \n",
    "– Multiplication  \n",
    "– Derivatives, del, div, curl  \n",
    "Tensors  \n",
    "– Tensors, rank, stress tensor  \n",
    "– Index notation, summation convention  \n",
    "– Addition, multiplication  \n",
    "– Special tensors, $\\delta_{ij}$ and $\\epsilon_{ijk}$  \n",
    "– Tensor calculus: gradient, divergence, curl, ..  \n",
    "\n",
    "Further reading/studying e.g: Reddy (2013) 2.2.1-2.2.3, 2.2.5, 2.2.6,\n",
    "2.4.1, 2.4.4, 2.4.5, 2.4.6, 2.4.8 (not co/contravariant), Lai, Rubin,\n",
    "Kremple (2010): 2.1-2.13, 2.16, 2.17, 2.27-2.32, 4.1-4.3,   \n",
    "Khan Academy – linear algebra, multivariate calculus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05678400-cecc-41f2-9264-c8b9527c29f4",
   "metadata": {},
   "source": [
    "### Try yourself \n",
    "- For this part of the lecture, try Exercise 7 and optional advanced Exercise 8  \n",
    "- Try to finish in the afternoon workshop: Exercise 2, 3, 5, 6, 7, 9\n",
    "- Additional practise: Exercise 1, 4  \n",
    "-  Advanced practise: Exercise 8, 10  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
